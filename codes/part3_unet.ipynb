{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff058fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "\n",
    "required = {'opencv-python'}\n",
    "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
    "missing = required - installed\n",
    "\n",
    "if missing:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', *missing], stdout=None)\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "from patchify import patchify, unpatchify\n",
    "import torch\n",
    "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
    "import torch.nn.functional as F  # All functions that don't have any parameters\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    ")  # Gives easier dataset managment and creates mini batches\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets  # Has standard datasets we can import in a nice way\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "# Albumentations\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from tqdm import tqdm\n",
    "from model import UNET\n",
    "\n",
    "from data_loader import Dataloader_trdp\n",
    "from utils import (\n",
    "    load_checkpoint,\n",
    "    load_checkpoint_pspnetlite,\n",
    "    save_checkpoint,\n",
    "    #get_loaders,\n",
    "    check_accuracy,\n",
    "    save_predictions_as_imgs,\n",
    "    predict,\n",
    "    store_predictions,\n",
    "    store_predictions_with_patching,\n",
    "    store_predictions_unet_improved\n",
    ")\n",
    "\n",
    "# Clean graphics memory\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e986c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyperparameters\n",
    "in_channel = 3\n",
    "num_classes = 1\n",
    "learning_rate = 1e-4\n",
    "batch_size = 1\n",
    "num_epochs = 2\n",
    "chip_dimension = 1024\n",
    "LOAD_MODEL = True\n",
    "TRAIN = False\n",
    "TEST = False\n",
    "SAVE = True\n",
    "# define threshold to filter weak predictions\n",
    "THRESHOLD = 0.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25d7b7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : 94 - Test: 283\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "train_dir  = Path('../../DATASET/dataset_pruebas/train')\n",
    "test_dir  = Path('../../DATASET/dataset_pruebas/validation')\n",
    "\n",
    "\n",
    "train_dir = Path('../../DATASET/archive/train_final')\n",
    "test_dir  = Path('../../DATASET/archive/val_final')\n",
    "\n",
    "\n",
    "csv_file = Path('./output_csvs/df_train_untidy.csv')\n",
    "csv_file_test = Path('./output_csvs/df_test_untidy.csv')\n",
    "\n",
    "\n",
    "csv_file = Path('./registros/output_csvs_dataset_prueba/df_train_untidy.csv')\n",
    "csv_file_test = Path('./registros/output_csvs_dataset_prueba/df_test_untidy.csv')\n",
    "'''\n",
    "\n",
    "#train_dir = Path('../../DATASET/archive/train_final')\n",
    "\n",
    "train_dir  = Path('../../DATASET/dataset_pruebas/train')\n",
    "#test_dir  = Path('../../DATASET/dataset_pruebas/validation')\n",
    "test_dir  = Path('../../DATASET/archive/val_final')\n",
    "\n",
    "#csv_file = Path('./output_csvs/df_train_untidy.csv')\n",
    "csv_file = Path('./registros/output_csvs_dataset_prueba/df_train_untidy.csv')\n",
    "#csv_file_test = Path('./registros/output_csvs_dataset_prueba/df_test_untidy.csv')\n",
    "\n",
    "csv_file_test = Path('./output_csvs/df_test_untidy.csv')\n",
    "\n",
    "root_dir  = train_dir\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "df_test = pd.read_csv(csv_file_test)\n",
    "\n",
    "\n",
    "sample_dir = Path('../../DATASET/SN7_buildings_train_sample')\n",
    "\n",
    "# Reconstructiontest_loader\n",
    "img_size = 1024\n",
    "# Chip size given batch_size\n",
    "chip_dim = ((img_size -1)//batch_size + 1)*2\n",
    "# number of Columns per chip\n",
    "columns = img_size / chip_dim\n",
    "# Needed patches to reconstruct original image\n",
    "patches_total = int(columns**2)\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "A.Normalize(mean=mean,std=std)\n",
    "#A.Rotate(limit=(-360, 360), interpolation=4, border_mode=4,p=1),\n",
    "\n",
    "\n",
    "transform = A.Compose(\n",
    "    [\n",
    "        #A.Resize(height=256, width=256),\n",
    "        \n",
    "        A.PadIfNeeded(min_height=chip_dimension,min_width=chip_dimension,value=0,p=1),\n",
    "        #A.RandomRotate90(p=1.0),\n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_set   = Dataloader_trdp(root_dir=train_dir,csv_file=csv_file,chip_dimension=chip_dimension,transform=transform)\n",
    "\n",
    "testing_set = Dataloader_trdp(root_dir=test_dir,csv_file=csv_file_test,chip_dimension=chip_dimension,transform=transform)\n",
    "\n",
    "#train_set, val_set = torch.utils.data.random_split(train_set, [round(0.7*len(train_set)),round(0.3*len(train_set))])\n",
    "\n",
    "train_loader = DataLoader(dataset = train_set, batch_size=batch_size, shuffle = False)\n",
    "#val_loader   = DataLoader(dataset = val_set, batch_size=batch_size, shuffle = False)\n",
    "test_loader  = DataLoader(dataset = testing_set, batch_size=batch_size, shuffle = False)\n",
    "\n",
    "print(f\"Train : {len(train_loader)} - Test: {len(test_loader)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5da0ef",
   "metadata": {},
   "source": [
    "\n",
    "# UNET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3599020f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.10.0\n",
      "Total params: 31M\n",
      "=> Loading checkpoint\n",
      "Model loaded successfully\n",
      " 0/283 \n",
      " 1/283 \n",
      " 2/283 \n",
      " 3/283 \n",
      " 4/283 \n",
      " 5/283 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_119648/2291186866.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m \u001b[0mloss_per_epoch_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_val_per_epoch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m '''\n",
      "\u001b[0;32m/tmp/ipykernel_119648/2291186866.py\u001b[0m in \u001b[0;36mtesting\u001b[0;34m(args, model, device, test_loader)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;31m#Aggregated per-pixel loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mloss_per_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# Convert to numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "import numpy as np\n",
    "print('PyTorch version:', torch.__version__)\n",
    "\n",
    "class configuration:\n",
    "    def __init__(self):\n",
    "        self.experiment_name = \"trdp1.001\"\n",
    "        self.pre_load = \"True\" ## Load dataset in memory\n",
    "        self.pre_trained = \"True\"\n",
    "        self.num_classes = num_classes\n",
    "        self.ignore_label = 255\n",
    "        self.lr = learning_rate  # 0.001 if pretrained. 0.1 if scratch\n",
    "        self.M = [] ##If training from scratch, reduce learning rate at some point\n",
    "        self.batch_size = batch_size  # Training batch size\n",
    "        self.test_batch_size = 4  # Test batch size\n",
    "        self.epoch = num_epochs ## Number of epochs\n",
    "        self.train_root = \"./VOC\"\n",
    "        self.download = False\n",
    "        self.seed = 271828\n",
    "\n",
    "\n",
    "## Create arguments object\n",
    "args = configuration()\n",
    "\n",
    "# Make sure to enable GPU acceleration!\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# Set random seed for reproducability\n",
    "torch.backends.cudnn.deterministic = True  # fix the GPU to deterministic mode\n",
    "torch.manual_seed(args.seed)  # CPU seed\n",
    "torch.cuda.manual_seed_all(args.seed)  # GPU seed\n",
    "random.seed(args.seed)  # python seed for image transformation\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "\n",
    "def _fast_hist(label_pred, label_true, num_classes):\n",
    "    mask = (label_true >= 0) & (label_true < num_classes)\n",
    "    hist = np.bincount(\n",
    "        num_classes * label_true[mask].astype(int) +\n",
    "        label_pred[mask], minlength=num_classes ** 2).reshape(num_classes, num_classes)\n",
    "    return hist\n",
    "\n",
    "def train_SemanticSeg(args, model, device, train_loader, optimizer, epoch):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    train_loss = []\n",
    "    counter = 1\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    gts_all, predictions_all = [], []\n",
    "\n",
    "    for batch_idx, (data) in enumerate(train_loader):\n",
    "        \n",
    "        images = data[\"raster_diff\"].float()\n",
    "        \n",
    "        mask = data[\"mask_diff\"].float()\n",
    "        \n",
    "        images, mask = images.to(device), mask.to(device).squeeze()\n",
    "\n",
    "        #Forward pass\n",
    "        outputs = model(images).squeeze()\n",
    "\n",
    "        \n",
    "        #Aggregated per-pixel loss\n",
    "        loss = criterion(outputs, mask)\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if counter % 15 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Learning rate: {:.6f}'.format(\n",
    "                epoch, int(counter * len(images)), len(train_loader.dataset),\n",
    "                100. * counter / len(train_loader), loss.item(),\n",
    "                optimizer.param_groups[0]['lr']))\n",
    "        counter = counter + 1\n",
    "        \n",
    "    return sum(train_loss) / len(train_loss)#, mean_iu\n",
    "        \n",
    "        \n",
    "def testing(args, model, device, test_loader):\n",
    "\n",
    "    # switch to train mode\n",
    "    model.eval()\n",
    "    loss_per_batch = []\n",
    "    test_loss = 0\n",
    "\n",
    "    ##We ignore index 255, i.e. object contours labeled with 255 in the val GT\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    gts_all, predictions_all = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data) in enumerate(test_loader):\n",
    "            print(f\" {batch_idx}/{len(test_loader)} \")\n",
    "            images = data[\"raster_diff\"].float()\n",
    "            mask = data[\"mask_diff\"].float()#type(torch.LongTensor)\n",
    "            images, mask = images.to(device), mask.to(device).squeeze()\n",
    "            \n",
    "            \n",
    "            #Forward pass\n",
    "            outputs = model(images).squeeze()\n",
    "            #outputs = outputs.clone().detach().cpu().numpy()\n",
    "    #        outputs = outputs.cpu().numpy()\n",
    "            outputs = ((outputs - outputs.min())/(outputs.max()-outputs.min()))\n",
    "            #outputs = np.round(outputs)\n",
    "            outputs[outputs>THRESHOLD] = 1 \n",
    "            outputs[outputs<=THRESHOLD] = 0\n",
    "            outputs = torch.round(outputs)\n",
    "            \n",
    "            #Aggregated per-pixel loss\n",
    "            loss = criterion(outputs, mask)\n",
    "            loss_per_batch.append(loss.item())\n",
    "            \n",
    "            # Convert to numpy\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            outputs = outputs.astype(\"int64\")\n",
    "            #predictions = np.round(predictions)\n",
    "            \n",
    "            mask = mask.data.cpu().numpy()\n",
    "            mask = mask.astype(\"int64\")\n",
    "            \n",
    "            '''\n",
    "            import matplotlib.pyplot as plt\n",
    "            plt.imshow(outputs)\n",
    "            np.unique(outputs)\n",
    "            \n",
    "            \n",
    "            preds = outputs.data.max(1)[1].squeeze(1).squeeze(0).cpu().numpy()\n",
    "            \n",
    "            mask = mask.data.cpu().numpy()\n",
    "            mask = mask.astype(\"int64\")\n",
    "            plt.imshow(mask)\n",
    "            \n",
    "            assert np.unique(mask) == np.unique(outputs*255)\n",
    "            '''\n",
    "            gts_all.append(mask)\n",
    "            predictions_all.append(255*outputs)\n",
    "            \n",
    "            if SAVE:\n",
    "                \n",
    "                images = \"outputs\"\n",
    "                labels = images+\"/predictions\"\n",
    "                true = images+\"/labels\"\n",
    "                \n",
    "                if not os.path.exists(images):\n",
    "                    os.makedirs(images)\n",
    "                if not os.path.exists(labels):\n",
    "                        os.makedirs(labels)\n",
    "                if not os.path.exists(true):\n",
    "                        os.makedirs(true)\n",
    "            \n",
    "                matplotlib.image.imsave(f\"{labels}/Pred_{batch_idx}.png\", outputs , cmap='gray')\n",
    "            \n",
    "                matplotlib.image.imsave(f\"{true}/True_{batch_idx}.png\", mask, cmap='gray')\n",
    "                    \n",
    "            \n",
    "\n",
    "    #test_loss /= len(test_loader.dataset)\n",
    "    loss_per_epoch = [np.average(loss_per_batch)]\n",
    "    \n",
    "\n",
    "    ##Compute Mean Intersection over Union (mIoU)\n",
    "    ##mIoU: Mean (of all classes) of intersection over union between prediction\n",
    "    ##and ground-truth\n",
    "\n",
    "    # Improved: https://towardsdatascience.com/intersection-over-union-iou-calculation-for-evaluating-an-image-segmentation-model-8b22e2e84686 \n",
    "    iou_scores = []\n",
    "    for lp, lt in zip(predictions_all, gts_all):\n",
    "        # Convert lp to cpu\n",
    "        #lp = lp.detach().cpu().numpy()\n",
    "        intersection = np.logical_and(lp.flatten(), lt.flatten())  \n",
    "        union = np.logical_or(lp.flatten(), lt.flatten())  \n",
    "        iou_score = np.sum(intersection) / np.sum(union)\n",
    "        iou_scores.append(iou_score)\n",
    "    \n",
    "    mean_iu = np.average(iou_scores)\n",
    "    \n",
    "    print('\\nTest set ({:.0f}): Average loss: {:.4f}, mIoU: {:.4f}\\n'.format(\n",
    "        len(test_loader.dataset), loss_per_epoch[-1], mean_iu)) \n",
    "    \n",
    "    ###########################################################################\n",
    "    # Store predictions\n",
    "\n",
    "    return loss_per_epoch, mean_iu, predictions_all, gts_all\n",
    "    \n",
    "\n",
    "model = UNET(in_channels=3, out_channels=1).to(device)\n",
    "\n",
    "print('Total params: %2.fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "    \n",
    "milestones = args.M\n",
    "#optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=1e-4)\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=0.1)\n",
    "\n",
    "import os\n",
    "import time\n",
    "loss_train_epoch = []\n",
    "loss_test_epoch = []\n",
    "acc_train_per_epoch = []\n",
    "acc_test_per_epoch = []\n",
    "new_labels = []\n",
    "\n",
    "cont = 0\n",
    "\n",
    "res_path = \"./metrics_\" + args.experiment_name\n",
    "\n",
    "\n",
    "filename = \"unet_7_dic_DATASET_PRUEBA_1_epochs_works.pth\" # my_checkpoint.pth.tar\n",
    "model_path = \"./models\" # + filename\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "if LOAD_MODEL:\n",
    "        load_checkpoint_pspnetlite(torch.load(\"models/\" + filename), model)\n",
    "    \n",
    "\n",
    "if not os.path.isdir(res_path):\n",
    "    os.makedirs(res_path)\n",
    "\n",
    "for epoch in range(1, args.epoch + 1):\n",
    "        st = time.time()\n",
    "        scheduler.step()    \n",
    "        # train for one epoch\n",
    "        if TRAIN:\n",
    "\n",
    "            print(\"Unet improved --> training, epoch \" + str(epoch))\n",
    "    \n",
    "            loss_per_epoch = train_SemanticSeg(args, model, device, train_loader, optimizer, epoch)\n",
    "    \n",
    "            loss_train_epoch += [loss_per_epoch]\n",
    "            \n",
    "            if epoch == args.epoch:\n",
    "                torch.save(model.state_dict(), \"models/\" + filename)\n",
    "    \n",
    "            np.save(res_path + '/' + 'LOSS_epoch_train.npy', np.asarray(loss_train_epoch))\n",
    "        \n",
    "        # TESTING\n",
    "        if TEST:\n",
    "            print(\"Unet improved ==> testing, epoch \" + str(epoch))\n",
    "            # test\n",
    "            loss_per_epoch_test, acc_val_per_epoch_i, a,b = testing(args, model, device, test_loader)\n",
    "    \n",
    "            loss_test_epoch += loss_per_epoch_test\n",
    "            acc_test_per_epoch += [acc_val_per_epoch_i]\n",
    "    \n",
    "    \n",
    "            if epoch == 1:\n",
    "                best_acc_val = acc_val_per_epoch_i\n",
    "    \n",
    "            else:\n",
    "                if acc_val_per_epoch_i > best_acc_val:\n",
    "                    best_acc_val = acc_val_per_epoch_i\n",
    "    \n",
    "    \n",
    "            np.save(res_path + '/' + 'LOSS_epoch_val.npy', np.asarray(loss_test_epoch))\n",
    "    \n",
    "            # save accuracies:\n",
    "            np.save(res_path + '/' + 'accuracy_per_epoch_val.npy', np.asarray(acc_test_per_epoch))\n",
    "            \n",
    "            cont += 1\n",
    "\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=0.1)\n",
    "    \n",
    "# PREDICT\n",
    "\n",
    "y_pred, true_pred = [], []\n",
    "\n",
    "loss_per_epoch_test, acc_val_per_epoch_i, y_pred, true_pred = testing(args, model, device, test_loader)\n",
    "\n",
    "'''\n",
    "y_pred = np.array(y_pred)\n",
    "true_pred = np.array()\n",
    "\n",
    "print(f\"y_pred sizes: {y_pred.shape} - true_pred sizes: {true_pred.shape}\")\n",
    "print(f\"y_pred pixel values: {np.unique(y_pred)}\")\n",
    "\n",
    "store_predictions_with_patching(y_pred, true_pred, 16)\n",
    "    \n",
    "\n",
    "for epoch in range(1, args.epoch + 1):\n",
    "    st = time.time()\n",
    "    scheduler.step()    \n",
    "    # train for one epoch\n",
    "    print(\"Unet improved ==> testing, epoch \" + str(epoch))\n",
    "    # test\n",
    "    loss_per_epoch_test, acc_val_per_epoch_i = testing(args, model, device, test_loader)\n",
    "\n",
    "    loss_test_epoch += loss_per_epoch_test\n",
    "    acc_test_per_epoch += [acc_val_per_epoch_i]\n",
    "\n",
    "\n",
    "    if epoch == 1:\n",
    "        best_acc_val = acc_val_per_epoch_i\n",
    "\n",
    "    else:\n",
    "        if acc_val_per_epoch_i > best_acc_val:\n",
    "            best_acc_val = acc_val_per_epoch_i\n",
    "\n",
    "\n",
    "    np.save(res_path + '/' + 'LOSS_epoch_val.npy', np.asarray(loss_test_epoch))\n",
    "\n",
    "    # save accuracies:\n",
    "    np.save(res_path + '/' + 'accuracy_per_epoch_val.npy', np.asarray(acc_test_per_epoch))\n",
    "    \n",
    "    cont += 1\n",
    "\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=0.1)\n",
    "\n",
    "# To delete temporal files\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(\"outputs\")\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94276746",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
