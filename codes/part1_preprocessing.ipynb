{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1b32d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/sebasmos/anaconda3/envs/sebasmos/lib/python3.9/site-packages (4.62.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "import pandas as pd \n",
    "import re\n",
    "from pathlib import Path\n",
    "import shapely\n",
    "import geopandas as gpd\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "tqdm.pandas();\n",
    "label_csv_path = Path('/home/sebasmos/Desktop/TRPD/DATASET/sn7_train_ground_truth_pix.csv')\n",
    "#os.chdir(label_csv_path)\n",
    "output_path = Path.cwd()\n",
    "output_csv_path = output_path/'output_csvs/'\n",
    "Path(output_csv_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f4e8d6",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89c5a761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            filename    id  \\\n",
      "0  global_monthly_2018_01_mosaic_L15-0331E-1257N_...    91   \n",
      "1  global_monthly_2018_01_mosaic_L15-0331E-1257N_...  1452   \n",
      "2  global_monthly_2018_01_mosaic_L15-0331E-1257N_...  1616   \n",
      "3  global_monthly_2018_01_mosaic_L15-0331E-1257N_...   950   \n",
      "4  global_monthly_2018_01_mosaic_L15-0331E-1257N_...  1765   \n",
      "\n",
      "                                            geometry  \n",
      "0  POLYGON ((814.9857745971531 845.6005742002744,...  \n",
      "1  POLYGON ((886.3093001581728 842.7000443374272,...  \n",
      "2  POLYGON ((930.1175056053326 840.4646877695341,...  \n",
      "3  POLYGON ((923.3884236379527 840.6308379401453,...  \n",
      "4  POLYGON ((926.2129765632562 838.8862611351069,...  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6664652 entries, 0 to 6664651\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Dtype \n",
      "---  ------    ----- \n",
      " 0   filename  object\n",
      " 1   id        int64 \n",
      " 2   geometry  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 152.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(label_csv_path)\n",
    "print(df.head())\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f12c299a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bec0777c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\r\n",
      "      - Validating: \u001b[32mOK\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0267e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7abeef3f8f64c4582cd2395966c01e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6664652 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>global_monthly_2018_01_mosaic_L15-0331E-1257N_...</td>\n",
       "      <td>91</td>\n",
       "      <td>POLYGON ((814.9857745971531 845.6005742002744,...</td>\n",
       "      <td>2018</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>global_monthly_2018_01_mosaic_L15-0331E-1257N_...</td>\n",
       "      <td>1452</td>\n",
       "      <td>POLYGON ((886.3093001581728 842.7000443374272,...</td>\n",
       "      <td>2018</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>global_monthly_2018_01_mosaic_L15-0331E-1257N_...</td>\n",
       "      <td>1616</td>\n",
       "      <td>POLYGON ((930.1175056053326 840.4646877695341,...</td>\n",
       "      <td>2018</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>global_monthly_2018_01_mosaic_L15-0331E-1257N_...</td>\n",
       "      <td>950</td>\n",
       "      <td>POLYGON ((923.3884236379527 840.6308379401453,...</td>\n",
       "      <td>2018</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>global_monthly_2018_01_mosaic_L15-0331E-1257N_...</td>\n",
       "      <td>1765</td>\n",
       "      <td>POLYGON ((926.2129765632562 838.8862611351069,...</td>\n",
       "      <td>2018</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename    id  \\\n",
       "0  global_monthly_2018_01_mosaic_L15-0331E-1257N_...    91   \n",
       "1  global_monthly_2018_01_mosaic_L15-0331E-1257N_...  1452   \n",
       "2  global_monthly_2018_01_mosaic_L15-0331E-1257N_...  1616   \n",
       "3  global_monthly_2018_01_mosaic_L15-0331E-1257N_...   950   \n",
       "4  global_monthly_2018_01_mosaic_L15-0331E-1257N_...  1765   \n",
       "\n",
       "                                            geometry  year month  \n",
       "0  POLYGON ((814.9857745971531 845.6005742002744,...  2018    01  \n",
       "1  POLYGON ((886.3093001581728 842.7000443374272,...  2018    01  \n",
       "2  POLYGON ((930.1175056053326 840.4646877695341,...  2018    01  \n",
       "3  POLYGON ((923.3884236379527 840.6308379401453,...  2018    01  \n",
       "4  POLYGON ((926.2129765632562 838.8862611351069,...  2018    01  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_date(string):\n",
    "    pattern = r'(\\d+)'\n",
    "    match = re.findall(pattern=pattern,string=string)\n",
    "    return (match[0],match[1])\n",
    "\n",
    "def extract_file_id(string):\n",
    "    pattern = r'_(L.+)'\n",
    "    match = re.findall(pattern=pattern,string=string)\n",
    "    return match[0]\n",
    "'''\n",
    "Extract year and month on separate columns\n",
    "'''\n",
    "df['year'],df['month'] = zip(*df['filename'].progress_map(extract_date))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0747f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a839b2a8d954f39885ad4158e304669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6664652 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>file_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>global_monthly_2018_01_mosaic_L15-0331E-1257N_...</td>\n",
       "      <td>91</td>\n",
       "      <td>POLYGON ((814.9857745971531 845.6005742002744,...</td>\n",
       "      <td>2018</td>\n",
       "      <td>01</td>\n",
       "      <td>L15-0331E-1257N_1327_3160_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>global_monthly_2018_01_mosaic_L15-0331E-1257N_...</td>\n",
       "      <td>1452</td>\n",
       "      <td>POLYGON ((886.3093001581728 842.7000443374272,...</td>\n",
       "      <td>2018</td>\n",
       "      <td>01</td>\n",
       "      <td>L15-0331E-1257N_1327_3160_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>global_monthly_2018_01_mosaic_L15-0331E-1257N_...</td>\n",
       "      <td>1616</td>\n",
       "      <td>POLYGON ((930.1175056053326 840.4646877695341,...</td>\n",
       "      <td>2018</td>\n",
       "      <td>01</td>\n",
       "      <td>L15-0331E-1257N_1327_3160_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>global_monthly_2018_01_mosaic_L15-0331E-1257N_...</td>\n",
       "      <td>950</td>\n",
       "      <td>POLYGON ((923.3884236379527 840.6308379401453,...</td>\n",
       "      <td>2018</td>\n",
       "      <td>01</td>\n",
       "      <td>L15-0331E-1257N_1327_3160_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>global_monthly_2018_01_mosaic_L15-0331E-1257N_...</td>\n",
       "      <td>1765</td>\n",
       "      <td>POLYGON ((926.2129765632562 838.8862611351069,...</td>\n",
       "      <td>2018</td>\n",
       "      <td>01</td>\n",
       "      <td>L15-0331E-1257N_1327_3160_13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename    id  \\\n",
       "0  global_monthly_2018_01_mosaic_L15-0331E-1257N_...    91   \n",
       "1  global_monthly_2018_01_mosaic_L15-0331E-1257N_...  1452   \n",
       "2  global_monthly_2018_01_mosaic_L15-0331E-1257N_...  1616   \n",
       "3  global_monthly_2018_01_mosaic_L15-0331E-1257N_...   950   \n",
       "4  global_monthly_2018_01_mosaic_L15-0331E-1257N_...  1765   \n",
       "\n",
       "                                            geometry  year month  \\\n",
       "0  POLYGON ((814.9857745971531 845.6005742002744,...  2018    01   \n",
       "1  POLYGON ((886.3093001581728 842.7000443374272,...  2018    01   \n",
       "2  POLYGON ((930.1175056053326 840.4646877695341,...  2018    01   \n",
       "3  POLYGON ((923.3884236379527 840.6308379401453,...  2018    01   \n",
       "4  POLYGON ((926.2129765632562 838.8862611351069,...  2018    01   \n",
       "\n",
       "                        file_id  \n",
       "0  L15-0331E-1257N_1327_3160_13  \n",
       "1  L15-0331E-1257N_1327_3160_13  \n",
       "2  L15-0331E-1257N_1327_3160_13  \n",
       "3  L15-0331E-1257N_1327_3160_13  \n",
       "4  L15-0331E-1257N_1327_3160_13  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Extract ID on separate column\n",
    "\n",
    " the geolocation of the building polygon is stored in a format known as Well Known Text (WKT).\n",
    " Since this dataset is about change detection in satellite imagery we expect that the number of \n",
    " polygons will increase as the year number increases, because the area in which the satellite \n",
    " image is being taken is being built, therefore the total number of polygons would increase.\n",
    "'''\n",
    "df['file_id'] = df['filename'].progress_map(extract_file_id)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19838c03",
   "metadata": {},
   "source": [
    "Create a pandas file which contains information of sn7_train_ground_truth_pix, separating date on separate columns: month,year, day, id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccb9947e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745628a8dafc4e2fbacabe920c2d5bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6664652 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Store when necessary \n",
    "flag = True\n",
    "if flag: \n",
    "    gdf = gpd.GeoDataFrame(df)\n",
    "    gdf['geometry'] = gdf['geometry'].progress_map(shapely.wkt.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "479f6a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.crs = 'EPSG:4326'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9da6135",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gdf.to_file(output_csv_path/\"global_geodataframe.gpkg\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fbe391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "from pathlib import Path\n",
    "import shapely\n",
    "import geopandas as gpd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from glob import glob\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4239e157",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ad8c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load split over training data\n",
    "train_dir = Path('../../DATASET/archive/train_final')\n",
    "test_dir = Path('../../DATASET/dataset_pruebas/validation')\n",
    "sample_dir = Path('../../DATASET/SN7_buildings_train_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0cfc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path.cwd()\n",
    "output_csv_path = output_path/'output_csvs/'\n",
    "Path(output_csv_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4850adfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_list_of_paths(directory):\n",
    "    paths_list = [path for path in Path.glob(directory,pattern = '**/*.*')]\n",
    "    return paths_list\n",
    "\n",
    "train_paths = extract_list_of_paths(directory=train_dir)\n",
    "test_paths = extract_list_of_paths(directory=test_dir)\n",
    "sample_paths = extract_list_of_paths(directory=sample_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589e08cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eabb615",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(train_paths[0]).replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5baed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_metadata_from_string(string): # change \"\"\\\"\" \n",
    "    # extracted groups\n",
    "    # full path - image_dir_name - sub_dir_name - fname - year - month - data_type - extension\n",
    "    pattern = r'/(t.+|v.+|sample+)/(L.+)/(\\w+)/(.+_(\\d+)_(\\d+)_m.+_\\d+_\\d+_\\d+)(?:_(\\w+))?.(\\w+)'\n",
    "    match = re.findall(pattern=pattern,string=string)\n",
    "    #print(match)\n",
    "    return match[0]\n",
    "\n",
    "def extract_metadata_from_list_of_paths(list_of_paths):\n",
    "    d_keys = ['parent_dir','image_dir_name','sub_dir_name','fname','year','month','data_type','extension']\n",
    "    d = {key:[] for key in d_keys}\n",
    "    d['full_path'] = []\n",
    "    for path in list_of_paths:        \n",
    "        path = str(path).replace(\"\\\\\", \"/\")\n",
    "        metadata = extract_metadata_from_string((path))\n",
    "        d['full_path'].append(path)\n",
    "        \n",
    "        for i,data in enumerate(metadata):\n",
    "            d[d_keys[i]].append(data)\n",
    "    return d\n",
    "# Extract information related to date, datatype, extension etc\n",
    "train_metadata_dict = extract_metadata_from_list_of_paths(train_paths)\n",
    "test_metadata_dict = extract_metadata_from_list_of_paths(test_paths)\n",
    "sample_metadata_dict = extract_metadata_from_list_of_paths(sample_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0de4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(train_metadata_dict)\n",
    "df_test = pd.DataFrame(test_metadata_dict)\n",
    "df_sample = pd.DataFrame(sample_metadata_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994f5e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metadata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8455f3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080efb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill out data_types = nulls with Images types, as all are iamges\n",
    "df_train.loc[df_train['data_type'] =='','data_type'] = 'Images'\n",
    "df_test.loc[df_test['data_type'] =='','data_type'] = 'Images'\n",
    "df_sample.loc[df_sample['data_type'] =='','data_type'] = 'Images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dab53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(input_dir):\n",
    "    list_of_paths = extract_list_of_paths(input_dir)\n",
    "    metadata_dict = extract_metadata_from_list_of_paths(list_of_paths)\n",
    "    df = pd.DataFrame(metadata_dict)\n",
    "    \n",
    "    df.loc[df['data_type'] =='','data_type'] = 'Images'\n",
    "    \n",
    "\n",
    "    # Identify Images that have UDM Masks\n",
    "    condition = (df['sub_dir_name'] == 'UDM_masks')\n",
    "    # Get the indices of the images that have udm\n",
    "    udm_indices = df.loc[condition].index\n",
    "    # Get list of unique file names that have UDMs\n",
    "    udm_fnames = list(df.loc[udm_indices,'fname'])\n",
    "    # Get all rows that match the file names\n",
    "    udm_mask = df['fname'].progress_map(lambda x: x in udm_fnames)\n",
    "    # Initialize has_udm column \n",
    "    df['has_udm'] = False\n",
    "    # Apply mask and update udm value\n",
    "    df.loc[udm_mask,'has_udm'] = True\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df41a773",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = get_metadata(train_dir)\n",
    "df_test = get_metadata(test_dir)\n",
    "df_sample = get_metadata(sample_dir)\n",
    "df_concat = pd.concat([df_train,df_test,df_sample]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91924b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(output_csv_path/'df_train.csv',index=False)\n",
    "df_test.to_csv(output_csv_path/'df_test.csv',index=False)\n",
    "df_sample.to_csv(output_csv_path/'df_sample.csv',index=False)\n",
    "df_concat.to_csv(output_csv_path/'df_concat.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d80f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855ac732",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "OUTPUT: Convert DF to dictionary,  asign None values for UDM masks\n",
    "'''\n",
    "def untidy_df(df):\n",
    "    \n",
    "    parent_dir = df['parent_dir']\n",
    "    im_dir_name = df['image_dir_name']\n",
    "    fname = df['fname']\n",
    "    year = df['year']\n",
    "    month = df['month']\n",
    "    has_udm = df['has_udm']\n",
    "    \n",
    "    images_masked = im_dir_name + '/images_masked/' + fname + '.tif'\n",
    "    \n",
    "    \n",
    "    # TO be changed: for no labeled data do not consider any labels\n",
    "    if parent_dir == 'test':\n",
    "            images = None\n",
    "            labels_buildings = None\n",
    "            labels_udm = None\n",
    "            labels_match = None\n",
    "            labels_match_pix = None\n",
    "            udm_masks = None\n",
    "    else:\n",
    "        if has_udm:\n",
    "            udm_masks = im_dir_name + '/UDM_masks/' + fname + '.tif'\n",
    "        else:\n",
    "            udm_masks = None\n",
    "\n",
    "\n",
    "        images = im_dir_name + '/images/' + fname + '.tif'\n",
    "        labels_buildings = im_dir_name + '/labels/' + fname + '_Buildings.geojson'\n",
    "        labels_udm = im_dir_name + '/labels/' + fname + '_UDM.geojson'\n",
    "        labels_match = im_dir_name + '/labels_match/' + fname + '_Buildings.geojson'\n",
    "        labels_match_pix = im_dir_name + '/labels_match_pix/' + fname + '_Buildings.geojson'\n",
    "\n",
    "    keys = ['parent_dir','image_dir_name','fname','year','month','has_udm','udm_masks','images','images_masked','labels_buildings','labels_udm','labels_match','labels_match_pix']\n",
    "    values = [parent_dir,im_dir_name,fname,year,month,has_udm,udm_masks,images,images_masked,labels_buildings,labels_udm,labels_match,labels_match_pix]\n",
    "    \n",
    "    return {k:v for (k,v) in zip(keys,values)}\n",
    "\n",
    "def get_untidy_frame(df):\n",
    "    # apply function on input dataframe\n",
    "    list_of_dicts = df.progress_apply(lambda x: untidy_df(x), axis=1)\n",
    "    # drop the duplicated columns\n",
    "    untidy_frame = pd.DataFrame.from_records(list_of_dicts).drop_duplicates()\n",
    "    # bask in all the glory of your untidy frame ;D\n",
    "    return untidy_frame\n",
    "\n",
    "test_untidy_df = get_untidy_frame(df_test)\n",
    "train_untidy_df = get_untidy_frame(df_train)\n",
    "sample_untidy_df = get_untidy_frame(df_sample)\n",
    "concat_untidy_df = get_untidy_frame(df_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b067daa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec25d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_untidy_df.to_csv(output_csv_path/'df_train_untidy.csv',index=False)\n",
    "test_untidy_df.to_csv(output_csv_path/'df_test_untidy.csv',index=False)\n",
    "sample_untidy_df.to_csv(output_csv_path/'df_sample_untidy.csv',index=False)\n",
    "concat_untidy_df.to_csv(output_csv_path/'df_concat_untidy.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f38df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_untidy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28afa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_untidy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8119b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c424a68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "85ba06c61cbad17d5eb881fa86d4853118e8f0a05f9f71ef265c6bff528eb8ae"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
