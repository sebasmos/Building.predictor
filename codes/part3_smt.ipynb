{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff058fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
    "import torch.nn.functional as F  # All functions that don't have any parameters\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    ")  # Gives easier dataset managment and creates mini batches\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets  # Has standard datasets we can import in a nice way\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset\n",
    "from torchvision import datasets, transforms, models\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from data_loader import Dataloader_trdp\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e986c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "in_channel = 3\n",
    "num_classes = 1\n",
    "learning_rate = 1e-3\n",
    "batch_size = 32\n",
    "num_epochs = 2\n",
    "chip_dimension = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25d7b7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = Path('../../DATASET/dataset_pruebas/train')\n",
    "test_dir  = Path('../../DATASET/dataset_pruebas/validation')\n",
    "\n",
    "\n",
    "csv_file = Path('/home/sebasmos/Desktop/TRPD/Multi-temporal.building.tracker/codes/registros/output_csvs_dataset_prueba/df_train_untidy.csv')\n",
    "csv_file_test = Path('/home/sebasmos/Desktop/TRPD/Multi-temporal.building.tracker/codes/registros/output_csvs_dataset_prueba/df_test_untidy.csv')\n",
    "\n",
    "root_dir  = train_dir\n",
    "df = pd.read_csv(csv_file)\n",
    "df_test = pd.read_csv(csv_file_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc928582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "A.Normalize(mean=mean,std=std)\n",
    "#A.Rotate(limit=(-360, 360), interpolation=4, border_mode=4,p=1),\n",
    "\n",
    "chip_dimension = 256\n",
    "\n",
    "transform = A.Compose(\n",
    "    [\n",
    "        A.PadIfNeeded(min_height=chip_dimension,min_width=chip_dimension,value=0,p=1),\n",
    "        #A.RandomRotate90(p=1.0),\n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bfce2554",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set   = Dataloader_trdp(root_dir=root_dir,csv_file=csv_file,chip_dimension=chip_dimension,transform=transform)\n",
    "\n",
    "testing_set = Dataloader_trdp(root_dir=root_dir,csv_file=csv_file_test,chip_dimension=chip_dimension,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "215d7b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_set): 1504\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "print(f\"len(train_set): {len(train_set)}\")\n",
    "#print(f\"len(testing_set): {len(testing_set)}\")\n",
    "\n",
    "for i in range(len(train_set)):\n",
    "    sample = train_set[i]\n",
    "    # verify dimensionality\n",
    "    print(sample['raster_diff'].shape, sample['mask_diff'].shape)\n",
    "    if i==2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8aeb1b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : 32 - Test: 16\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = torch.utils.data.random_split(train_set, [1000,504])\n",
    "\n",
    "train_loader = DataLoader(dataset = train_set, batch_size=batch_size, shuffle = False)\n",
    "test_loader = DataLoader(dataset = test_set, batch_size=batch_size, shuffle = False)\n",
    "\n",
    "\n",
    "print(f\"Train : {len(train_loader)} - Test: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b04e34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc5da0ef",
   "metadata": {},
   "source": [
    "\n",
    "# PSNNETLITE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f86a8b0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.10.0\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "import numpy as np\n",
    "print('PyTorch version:', torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e631de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class configuration:\n",
    "    def __init__(self):\n",
    "        self.experiment_name = \"trdp1.001\"\n",
    "        self.pre_load = \"True\" ## Load dataset in memory\n",
    "        self.pre_trained = \"True\"\n",
    "        self.num_classes = 2\n",
    "        self.ignore_label = 255\n",
    "        self.lr = 0.001  # 0.001 if pretrained. 0.1 if scratch\n",
    "        self.M = [] ##If training from scratch, reduce learning rate at some point\n",
    "        self.batch_size = 16  # Training batch size\n",
    "        self.test_batch_size = 4  # Test batch size\n",
    "        self.epoch = 1 ## Number of epochs\n",
    "        self.train_root = \"./VOC\"\n",
    "        self.download = False\n",
    "        self.seed = 271828\n",
    "\n",
    "\n",
    "## Create arguments object\n",
    "args = configuration()\n",
    "\n",
    "# Make sure to enable GPU acceleration!\n",
    "device = 'cuda'\n",
    "\n",
    "# Set random seed for reproducability\n",
    "torch.backends.cudnn.deterministic = True  # fix the GPU to deterministic mode\n",
    "torch.manual_seed(args.seed)  # CPU seed\n",
    "torch.cuda.manual_seed_all(args.seed)  # GPU seed\n",
    "random.seed(args.seed)  # python seed for image transformation\n",
    "np.random.seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dd058f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSPNetLite(nn.Module):\n",
    "    def __init__(self, args, num_classes, pretrained=True, use_aux=True):\n",
    "        super(PSPNetLite, self).__init__()\n",
    "        self.use_aux = use_aux\n",
    "        \n",
    "        #### TO FILL: define pytorch default resnet-18 architecture (pretrained and not) \n",
    "        if pretrained==\"True\":\n",
    "            resnet = models.resnet18(pretrained=True) #\n",
    "        else:\n",
    "            resnet = models.resnet18(pretrained=False) #\n",
    "\n",
    "        self.layer0 = nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu, resnet.maxpool)\n",
    "        self.layer1, self.layer2, self.layer3, self.layer4 = resnet.layer1, resnet.layer2, resnet.layer3, resnet.layer4\n",
    "\n",
    "        for n, m in self.layer3.named_modules():\n",
    "            if 'conv2' in n:\n",
    "                m.dilation, m.padding, m.stride = (2, 2), (2, 2), (1, 1)\n",
    "        for n, m in self.layer4.named_modules():\n",
    "            if 'conv2' in n:\n",
    "                m.dilation, m.padding, m.stride = (4, 4), (4, 4), (1, 1)\n",
    "\n",
    "        ##Pooling module: simplification of Pyramid Pooling Module of PSPnet\n",
    "        self.pm = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(3),\n",
    "            nn.Conv2d(512, 256, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(256, momentum=.95),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        ## Final classifier to get per-pixel predictions\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(768, 512, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512, momentum=.95), #\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Conv2d(512, 1, kernel_size=1)\n",
    "        )\n",
    "     \n",
    "    #### To fill: write the forward pass function:\n",
    "    #### layer0 --> layer1 --> layer2 --> layer3 --> layer4--> pm --> final\n",
    "    def forward(self, x):\n",
    "        x_size = x.size()\n",
    "\n",
    "        x = self.layer0(x) #layer0\n",
    "        x = self.layer1(x) #layer1\n",
    "        x = self.layer2(x) #layer2\n",
    "        x = self.layer3(x) #layer3\n",
    "        \n",
    "        x1 = self.layer4(x)\n",
    "        x2 = self.pm(x1)\n",
    "\n",
    "        # Concatenate layer4 features with upsampled Pooling Module features\n",
    "        x = self.final(torch.cat((x1, F.interpolate(x2, x1.size()[2:], mode='bilinear')), dim=1)) #\n",
    "        ##return prediction after bilinear upsampling to original size\n",
    "        return F.interpolate(x, x_size[2:], mode='bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8f0fe92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fast_hist(label_pred, label_true, num_classes):\n",
    "    mask = (label_true >= 0) & (label_true < num_classes)\n",
    "    hist = np.bincount(\n",
    "        num_classes * label_true[mask].astype(int) +\n",
    "        label_pred[mask], minlength=num_classes ** 2).reshape(num_classes, num_classes)\n",
    "    return hist\n",
    "\n",
    "def train_SemanticSeg(args, model, device, train_loader, optimizer, epoch):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    train_loss = []\n",
    "    counter = 1\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    gts_all, predictions_all = [], []\n",
    "\n",
    "    for batch_idx, (data) in enumerate(train_loader):\n",
    "        \n",
    "        images = data[\"raster_diff\"].float()\n",
    "        \n",
    "        mask = data[\"mask_diff\"].float()\n",
    "        \n",
    "        images, mask = images.to(device), mask.to(device).squeeze()\n",
    "\n",
    "        #Forward pass\n",
    "        outputs = model(images).squeeze()\n",
    "\n",
    "        \n",
    "        #Aggregated per-pixel loss\n",
    "        loss = criterion(outputs, mask)\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if counter % 15 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Learning rate: {:.6f}'.format(\n",
    "                epoch, int(counter * len(images)), len(train_loader.dataset),\n",
    "                100. * counter / len(train_loader), loss.item(),\n",
    "                optimizer.param_groups[0]['lr']))\n",
    "        counter = counter + 1\n",
    "    \n",
    "    return sum(train_loss) / len(train_loss)#, mean_iu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e011a9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(args, model, device, test_loader):\n",
    "\n",
    "    # switch to train mode\n",
    "    model.eval()\n",
    "    loss_per_batch = []\n",
    "    test_loss = 0\n",
    "\n",
    "\n",
    "    ##We ignore index 255, i.e. object contours labeled with 255 in the val GT\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    gts_all, predictions_all = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data) in enumerate(test_loader):\n",
    "            images = data[\"raster_diff\"].float()\n",
    "            mask = data[\"mask_diff\"].float()#type(torch.LongTensor)\n",
    "            images, mask = images.to(device), mask.to(device).squeeze()\n",
    "            outputs = model(images).squeeze()\n",
    "\n",
    "            #Aggregated per-pixel loss\n",
    "            loss = criterion(outputs, mask)\n",
    "            loss_per_batch.append(loss.item())\n",
    "\n",
    "            preds = outputs.data.max(1)[1].squeeze(1).squeeze(0).cpu().numpy()\n",
    "            gts_all.append(mask.data.squeeze(0).cpu().numpy())\n",
    "            predictions_all.append(preds)\n",
    "\n",
    "    #test_loss /= len(test_loader.dataset)\n",
    "    loss_per_epoch = [np.average(loss_per_batch)]\n",
    "\n",
    "    ##Compute Mean Intersection over Union (mIoU)\n",
    "    ##mIoU: Mean (of all classes) of intersection over union between prediction\n",
    "    ##and ground-truth\n",
    "    hist = np.zeros((args.num_classes, args.num_classes))\n",
    "    for lp, lt in zip(predictions_all, gts_all):\n",
    "        hist += _fast_hist(lp.flatten(), lt.flatten(), args.num_classes)\n",
    "\n",
    "    iu = np.diag(hist) / (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n",
    "    mean_iu = np.nanmean(iu)\n",
    "\n",
    "    print('\\nTest set ({:.0f}): Average loss: {:.4f}, mIoU: {:.4f}\\n'.format(\n",
    "        len(test_loader.dataset), loss_per_epoch[-1], mean_iu))\n",
    "\n",
    "    return (loss_per_epoch, mean_iu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad7da172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 15M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PSPNetLite(\n",
       "  (layer0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (pm): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=3)\n",
       "    (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.95, affine=True, track_running_stats=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (final): Sequential(\n",
       "    (0): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.95, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PSPNetLite(1, num_classes=num_classes, pretrained=args.pre_trained).to(device)\n",
    "print('Total params: %2.fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5cc62bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "milestones = args.M\n",
    "#optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=1e-4)\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4bb3875a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSPnetLite training, epoch 1\n",
      "Train Epoch: 1 [480/1000 (47%)]\tLoss: -541.812744, Learning rate: 0.001000\n",
      "Train Epoch: 1 [960/1000 (94%)]\tLoss: -897.527100, Learning rate: 0.001000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "loss_train_epoch = []\n",
    "loss_test_epoch = []\n",
    "acc_train_per_epoch = []\n",
    "acc_test_per_epoch = []\n",
    "new_labels = []\n",
    "\n",
    "cont = 0\n",
    "\n",
    "res_path = \"./metrics_\" + args.experiment_name\n",
    "\n",
    "if not os.path.isdir(res_path):\n",
    "    os.makedirs(res_path)\n",
    "\n",
    "for epoch in range(1, args.epoch + 1):\n",
    "    st = time.time()\n",
    "    scheduler.step()\n",
    "    # train for one epoch\n",
    "    print(\"PSPnetLite training, epoch \" + str(epoch))\n",
    "\n",
    "    loss_per_epoch = train_SemanticSeg(args, model, device, train_loader, optimizer, epoch)\n",
    "\n",
    "    loss_train_epoch += [loss_per_epoch]\n",
    "    '''\n",
    "    # test\n",
    "    loss_per_epoch_test, acc_val_per_epoch_i = testing(args, model, device, test_loader)\n",
    "\n",
    "    loss_test_epoch += loss_per_epoch_test\n",
    "    acc_test_per_epoch += [acc_val_per_epoch_i]\n",
    "\n",
    "\n",
    "    if epoch == 1:\n",
    "        best_acc_val = acc_val_per_epoch_i\n",
    "\n",
    "    else:\n",
    "        if acc_val_per_epoch_i > best_acc_val:\n",
    "            best_acc_val = acc_val_per_epoch_i\n",
    "\n",
    "    if epoch == args.epoch:\n",
    "        torch.save(model.state_dict(), \"mySemanticSegModelPreTrained.pth\")\n",
    "        #torch.save(model.state_dict(), \"mySemanticSegModelScratch.pth\")\n",
    "\n",
    "    np.save(res_path + '/' + 'LOSS_epoch_train.npy', np.asarray(loss_train_epoch))\n",
    "    np.save(res_path + '/' + 'LOSS_epoch_val.npy', np.asarray(loss_test_epoch))\n",
    "\n",
    "    # save accuracies:\n",
    "    np.save(res_path + '/' + 'accuracy_per_epoch_val.npy', np.asarray(acc_test_per_epoch))\n",
    "    '''\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "16fdd83b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 8192 but corresponding boolean dimension is 2097152",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10878/3026760725.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mloss_per_epoch_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_val_per_epoch_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_10878/2749560133.py\u001b[0m in \u001b[0;36mtesting\u001b[0;34m(args, model, device, test_loader)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgts_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mhist\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0m_fast_hist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0miu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_10878/482917504.py\u001b[0m in \u001b[0;36m_fast_hist\u001b[0;34m(label_pred, label_true, num_classes)\u001b[0m\n\u001b[1;32m      3\u001b[0m     hist = np.bincount(\n\u001b[1;32m      4\u001b[0m         \u001b[0mnum_classes\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlabel_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         label_pred[mask], minlength=num_classes ** 2).reshape(num_classes, num_classes)\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 8192 but corresponding boolean dimension is 2097152"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(1, args.epoch + 1):\n",
    "    \n",
    "    loss_per_epoch_test, acc_val_per_epoch_i = testing(args, model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a92d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "##Accuracy\n",
    "acc_test = np.load(res_path + '/' + 'accuracy_per_epoch_val.npy')\n",
    "\n",
    "#Loss per epoch\n",
    "loss_train = np.load(res_path + '/' + 'LOSS_epoch_train.npy')\n",
    "loss_test = np.load(res_path + '/' + 'LOSS_epoch_val.npy')\n",
    "\n",
    "numEpochs = len(acc_test)\n",
    "epochs = range(numEpochs)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(epochs, acc_test, label='Test, max acc: ' + str(np.max(acc_test)))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(epochs, loss_test, label='Test, min loss: ' + str(np.min(loss_test)))\n",
    "plt.plot(epochs, loss_train, label='Train, min loss: ' + str(np.min(loss_train)))\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562872f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "        return tensor\n",
    "\n",
    "\n",
    "def visualizeSegmentation(args, model, device, test_loader, imageDenormalize, voc_palette):\n",
    "\n",
    "    # switch to train mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data) in enumerate(test_loader):\n",
    "\n",
    "            images = data[\"raster_diff\"].float()\n",
    "            mask = data[\"mask_diff\"].float()\n",
    "\n",
    "            images, mask = images.to(device), mask.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            plt.figure(batch_idx)\n",
    "\n",
    "            for i in range(0, images.size(0)):\n",
    "\n",
    "\n",
    "                image_np = (255*(imageDenormalize(images[i,...]).data.permute(1,2,0).cpu().numpy())).astype(np.uint8)\n",
    "                gt_np = mask[i,...].squeeze().data.cpu().numpy()\n",
    "                pred_np = outputs[i,...].data.max(0)[1].squeeze_(0).byte().cpu().numpy()\n",
    "\n",
    "                img_pil = Image.fromarray(image_np)\n",
    "\n",
    "                gt_np_color = np.stack((gt_np.copy(), gt_np.copy(), gt_np.copy()), axis=2)\n",
    "                pred_np_color = np.stack((pred_np.copy(), pred_np.copy(), pred_np.copy()), axis=2)\n",
    "\n",
    "\n",
    "                for j in range(0, 1):\n",
    "                    idx_tuple = np.where(gt_np == j)\n",
    "                    gt_np_color[idx_tuple[0], idx_tuple[1], 0] = colors[j][0]\n",
    "                    gt_np_color[idx_tuple[0], idx_tuple[1], 1] = colors[j][1]\n",
    "                    gt_np_color[idx_tuple[0], idx_tuple[1], 2] = colors[j][2]\n",
    "\n",
    "                    idx_tuple2 = np.where(pred_np == j)\n",
    "                    pred_np_color[idx_tuple2[0], idx_tuple2[1], 0] = colors[j][0]\n",
    "                    pred_np_color[idx_tuple2[0], idx_tuple2[1], 1] = colors[j][1]\n",
    "                    pred_np_color[idx_tuple2[0], idx_tuple2[1], 2] = colors[j][2]\n",
    "\n",
    "\n",
    "                plt.subplot(args.test_batch_size, 3, i * 3 + 1)\n",
    "                plt.imshow(img_pil)\n",
    "                plt.subplot(args.test_batch_size, 3, i * 3 + 2)\n",
    "                plt.imshow(gt_np_color)\n",
    "                plt.subplot(args.test_batch_size, 3, i * 3 + 3)\n",
    "                plt.imshow(pred_np_color)\n",
    "\n",
    "                \n",
    "            if batch_idx>7:\n",
    "                plt.show()\n",
    "                break\n",
    "\n",
    "imageDenormalize = DeNormalize(mean,std)\n",
    "\n",
    "## Color palette for visualization of the 21 classes\n",
    "colors = np.array([[0, 0, 0], [128, 0, 0]])\n",
    "\n",
    "model.load_state_dict(torch.load(\"mySemanticSegModelPreTrained.pth\"))\n",
    "#model.load_state_dict(torch.load(\"mySemanticSegModelScratch.pth\"))\n",
    "\n",
    "print('Total params: %2.fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "\n",
    "cont = 0\n",
    "\n",
    "visualizeSegmentation(args, model, device, test_loader, imageDenormalize, colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848d9dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions_as_imgs():#()\n",
    "#        loader, model, folder=\"/home/sebasmos/Desktop/TRPD/DATASET/segmented_imgs/\", device=\"cuda\"\n",
    "#):\n",
    "    model.eval()\n",
    "    for idx, data in enumerate(loader):\n",
    "                    \n",
    "        x = data[\"raster_diff\"].float()\n",
    "        y = data[\"mask_diff\"].float()\n",
    "        x = x.to(device=device)\n",
    "        with torch.no_grad():\n",
    "            preds = torch.sigmoid(model(x))\n",
    "            preds = (preds > 0.5).float()\n",
    "        torchvision.utils.save_image(preds, f\"{folder}/pred_{idx}.png\")\n",
    "        torchvision.utils.save_image(y.unsqueeze(1), f\"{folder}{idx}.png\")\n",
    "\n",
    "    model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
