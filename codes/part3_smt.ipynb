{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff058fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
    "import torch.nn.functional as F  # All functions that don't have any parameters\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    ")  # Gives easier dataset managment and creates mini batches\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets  # Has standard datasets we can import in a nice way\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset\n",
    "\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from data_loader import Dataloader_trdp\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e986c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "in_channel = 3\n",
    "num_classes = 2\n",
    "learning_rate = 1e-3\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "chip_dimension = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25d7b7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = Path('../DATASET/dataset_pruebas/train')\n",
    "test_dir = Path('../DATASET/dataset_pruebas/validation')\n",
    "sample_dir = Path('../DATASET/SN7_buildings_train_sample')\n",
    "\n",
    "root_dir  = train_dir\n",
    "csv_file = Path('../output_csvs/df_train_untidy.csv')\n",
    "csv_file_test = Path('../output_csvs/df_test_untidy.csv')\n",
    "df = pd.read_csv(csv_file)\n",
    "df_test = pd.read_csv(csv_file_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc928582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "A.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "A.Rotate(limit=(-360, 360), interpolation=4, border_mode=4,p=0),\n",
    "\n",
    "chip_dimension = 256\n",
    "\n",
    "transform = A.Compose(\n",
    "    [\n",
    "        A.PadIfNeeded(min_height=chip_dimension,min_width=chip_dimension,value=0,p=1),\n",
    "        A.RandomRotate90(p=1.0),\n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfce2554",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set   = Dataloader_trdp(root_dir=root_dir,csv_file=csv_file,chip_dimension=chip_dimension,transform=transform)\n",
    "\n",
    "testing_set = Dataloader_trdp(root_dir=root_dir,csv_file=csv_file_test,chip_dimension=chip_dimension,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "215d7b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_set): 1504\n",
      "len(testing_set): 0\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n",
      "torch.Size([3, 256, 256]) torch.Size([1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "print(f\"len(train_set): {len(train_set)}\")\n",
    "#print(f\"len(testing_set): {len(testing_set)}\")\n",
    "\n",
    "for i in range(len(train_set)):\n",
    "    sample = train_set[i]\n",
    "    # verify dimensionality\n",
    "    print(sample['raster_diff'].shape, sample['mask_diff'].shape)\n",
    "    if i==15:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8aeb1b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = torch.utils.data.random_split(train_set, [1000,504])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b04e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train_set, batch_size=batch_size, shuffle = True)\n",
    "test_loader = DataLoader(dataset = test_set, batch_size=batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6682f4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86a8b0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train Network\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Get data to cuda if possible\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Cost at epoch {epoch} is {sum(losses)/len(losses)}\")\n",
    "\n",
    "# Check accuracy on training to see how good our model is\n",
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "        print(\n",
    "            f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\"\n",
    "        )\n",
    "\n",
    "    model.train()\n",
    "\n",
    "\n",
    "print(\"Checking accuracy on Training Set\")\n",
    "check_accuracy(train_loader, model)\n",
    "\n",
    "print(\"Checking accuracy on Test Set\")\n",
    "check_accuracy(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e631de6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
